# Budget Notion Configuration Example
# Copy this file to .env and fill in your values

# Repository Configuration
# Options: "notion" or "sqlite"
REPOSITORY_TYPE=sqlite

# Notion API Configuration (required if REPOSITORY_TYPE=notion)
NOTION_TOKEN=your_notion_integration_token_here
NOTION_DATABASE_ID=your_notion_database_id_here

# SQLite Configuration (used if REPOSITORY_TYPE=sqlite)
SQLITE_DB_PATH=data/transactions.db

# Application Configuration
DEFAULT_CATEGORY=Uncategorized
LOG_LEVEL=INFO
ENVIRONMENT=development

# ===================================================================
# LLM Configuration (Unified for all providers)
# ===================================================================

# LLM Provider Selection
# Options: "ollama", "openai", "anthropic", "google", "litellm"
LLM_PROVIDER=ollama

# Model Identifier (provider-specific)
# Examples:
#   Ollama:    llama3.1:8b, llama3.1:70b, mistral:7b
#   OpenAI:    gpt-4, gpt-4-turbo, gpt-3.5-turbo
#   Anthropic: claude-3-5-sonnet-20241022, claude-3-opus-20240229, claude-3-haiku-20240307
#   Google:    gemini-1.5-pro, gemini-1.5-flash
#   Groq:      groq/llama-3.1-8b-instant, groq/mixtral-8x7b-32768
LLM_MODEL=llama3.1:8b

# API Key (required for commercial providers, not needed for Ollama)
# Get your API keys from:
#   OpenAI:    https://platform.openai.com/api-keys
#   Anthropic: https://console.anthropic.com/settings/keys
#   Google:    https://makersuite.google.com/app/apikey
#   Groq:      https://console.groq.com/keys
# LLM_API_KEY=

# Base URL (for Ollama or custom endpoints)
LLM_BASE_URL=http://localhost:11434

# Request timeout in seconds
LLM_TIMEOUT=120

# Sampling temperature (0.0 = deterministic, 1.0 = creative)
# Recommended: 0.1 for categorization tasks
LLM_TEMPERATURE=0.1

# Batch size for transaction categorization
# Higher = faster but uses more tokens
LLM_BATCH_SIZE=35

# Confidence threshold for review (0.0 - 1.0)
# Transactions with confidence below this value will be flagged for review
AI_CONFIDENCE_THRESHOLD=0.7

# ===================================================================
# Example Configurations for Different Providers
# ===================================================================

# Example 1: Ollama (Local, Free) - DEFAULT
# LLM_PROVIDER=ollama
# LLM_MODEL=llama3.1:8b
# LLM_BASE_URL=http://localhost:11434

# Example 2: OpenAI GPT-3.5-turbo (Fast, Cheap)
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-3.5-turbo
# LLM_API_KEY=sk-...

# Example 3: OpenAI GPT-4 (Best Quality, Expensive)
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4
# LLM_API_KEY=sk-...

# Example 4: Anthropic Claude 3.5 Sonnet (Balanced)
# LLM_PROVIDER=anthropic
# LLM_MODEL=claude-3-5-sonnet-20241022
# LLM_API_KEY=sk-ant-...

# Example 5: Google Gemini (Good Quality, Cheap)
# LLM_PROVIDER=google
# LLM_MODEL=gemini-1.5-flash
# LLM_API_KEY=...

# Example 6: Groq (Ultra-Fast, Free Tier)
# LLM_PROVIDER=litellm
# LLM_MODEL=groq/llama-3.1-8b-instant
# LLM_API_KEY=gsk_...

# Example 7: Custom LiteLLM Configuration
# LLM_PROVIDER=litellm
# LLM_MODEL=gpt-3.5-turbo  # or any LiteLLM-supported model
# LLM_API_KEY=your_api_key
# LLM_BASE_URL=  # optional for custom endpoints

# ===================================================================
# Cost Estimates (1000 transactions/month, ~250 tokens per transaction)
# ===================================================================
# Ollama (local):           $0/month (free, requires local hardware)
# Groq:                     ~$0.10/month
# GPT-3.5-turbo:            ~$0.50/month
# Gemini 1.5 Flash:         ~$0.75/month
# Claude 3 Haiku:           ~$2.50/month
# Claude 3.5 Sonnet:        ~$4.50/month
# GPT-4:                    ~$25/month
# ===================================================================

# Security (optional)
# ENCRYPTION_KEY=generate_a_secure_key_here

# Docker Secrets (alternative to environment variables)
# When using Docker, you can use these files instead:
# NOTION_TOKEN_FILE=/run/secrets/notion_token
# NOTION_DATABASE_ID_FILE=/run/secrets/notion_database_id
# ENCRYPTION_KEY_FILE=/run/secrets/encryption_key
